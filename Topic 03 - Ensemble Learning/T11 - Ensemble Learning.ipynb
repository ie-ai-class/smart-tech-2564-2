{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_wine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "dataObj = load_wine()\n",
    "X = dataObj.data\n",
    "y = dataObj.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with features\n",
    "dfori = pd.DataFrame(X)\n",
    "dfori.columns = dataObj.feature_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add class column\n",
    "dfori.insert(loc=0, column=\"Class\", value=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfori.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter class 0 and 1\n",
    "filt = (dfori[\"Class\"] == 0) | (dfori[\"Class\"] == 1)\n",
    "df = dfori.loc[filt]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract two features\n",
    "X = df[[\"alcohol\", \"malic_acid\"]].values\n",
    "y = df[\"Class\"].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=1, stratify=y\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize data\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "lr = LogisticRegression(C=0.005, random_state=0)\n",
    "dt = DecisionTreeClassifier(max_depth=2, criterion=\"entropy\", random_state=0)\n",
    "knn = KNeighborsClassifier(n_neighbors=1, p=2, metric=\"minkowski\")\n",
    "estimators = [(\"lr\", lr), (\"dt\", dt), (\"knn\", knn)]\n",
    "\n",
    "\n",
    "vc = VotingClassifier(estimators=estimators, voting=\"soft\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and displaying results\n",
    "names = [\n",
    "    \"Logistic Regression\",\n",
    "    \"Decision Tree\",\n",
    "    \"K-Nearest Neighbor\",\n",
    "    \"Voting Classifier\",\n",
    "]\n",
    "clfs = [lr, dt, knn, vc]\n",
    "accs = []\n",
    "misses = []\n",
    "\n",
    "for clf in clfs:\n",
    "    clf.fit(X_train_std, y_train)\n",
    "    y_pred = clf.predict(X_test_std)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    sumMiss = (y_test != y_pred).sum()\n",
    "    accs.append(acc)\n",
    "    misses.append(sumMiss)\n",
    "\n",
    "data = {\"names\": names, \"ACC\": accs, \"miss\": misses}\n",
    "\n",
    "dfResult = pd.DataFrame(data)\n",
    "display(dfResult)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision surface\n",
    "from itertools import product\n",
    "\n",
    "all_clf = clfs\n",
    "clf_labels = names\n",
    "\n",
    "X_train = X_train_std\n",
    "X_test = X_test_std\n",
    "\n",
    "x_min = X_test[:, 0].min() - 1\n",
    "x_max = X_test[:, 0].max() + 1\n",
    "y_min = X_test[:, 1].min() - 1\n",
    "y_max = X_test[:, 1].max() + 1\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "f, axarr = plt.subplots(nrows=2, ncols=2, sharex=\"col\", sharey=\"row\", figsize=(10, 8))\n",
    "\n",
    "for idx, clf, tt in zip(product([0, 1], [0, 1]), all_clf, clf_labels):\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    axarr[idx[0], idx[1]].contourf(xx, yy, Z, alpha=0.3)\n",
    "\n",
    "    axarr[idx[0], idx[1]].scatter(\n",
    "        X_test[y_test == 0, 0], X_test[y_test == 0, 1], c=\"blue\", marker=\"^\", s=50\n",
    "    )\n",
    "\n",
    "    axarr[idx[0], idx[1]].scatter(\n",
    "        X_test[y_test == 1, 0], X_test[y_test == 1, 1], c=\"red\", marker=\"o\", s=50\n",
    "    )\n",
    "\n",
    "    axarr[idx[0], idx[1]].set_title(tt)\n",
    "    axarr[idx[0], idx[1]].set_xlabel(\"Alcohol\")\n",
    "    axarr[idx[0], idx[1]].set_ylabel(\"Malic Acid\")\n",
    "\n",
    "plt.tight_layout(pad=3.0)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be725e0de8fb3f5fda9b0118bdf797fa9814e28e467c1cce77c5b9910d8a1786"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
