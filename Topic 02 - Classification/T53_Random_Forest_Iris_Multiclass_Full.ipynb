{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Random Forest\r\n",
    "- Iris dataset\r\n",
    "- All features\r\n",
    "- Multiclass"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from sklearn import datasets\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "from PlotFunction import plot_decision_surface_train_test\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn import tree"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "import os\r\n",
    "imagePath = os.path.join(os.getcwd(),'Images')\r\n",
    "if (not(os.path.isdir(imagePath))):\r\n",
    "    os.mkdir(imagePath)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "# Read data\r\n",
    "iris = datasets.load_iris()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "# Extract all columns\r\n",
    "X = iris.data\r\n",
    "y = iris.target"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "# Split data into training and testing data\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(\r\n",
    "    X, y, test_size=0.3, random_state=1, stratify=y\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "# Standardization\r\n",
    "sc = StandardScaler()\r\n",
    "sc.fit(X_train)\r\n",
    "X_train_std = sc.transform(X_train)\r\n",
    "X_test_std = sc.transform(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "paramSetAll = {\r\n",
    "    \"ex1\": {\r\n",
    "        \"criterion\": \"gini\",\r\n",
    "        \"n_estimators\": 25,\r\n",
    "        \"max_samples\": None,\r\n",
    "        \"max_features\": \"auto\",\r\n",
    "        \"max_depth\": None,\r\n",
    "    },\r\n",
    "    \"ex2\": {\r\n",
    "        \"criterion\": \"gini\",\r\n",
    "        \"n_estimators\": 100,\r\n",
    "        \"max_samples\": None,\r\n",
    "        \"max_features\": \"auto\",\r\n",
    "        \"max_depth\": 2,\r\n",
    "    },\r\n",
    "    \"ex3\": {\r\n",
    "        \"criterion\": \"gini\",\r\n",
    "        \"n_estimators\": 1000,\r\n",
    "        \"max_samples\": None,\r\n",
    "        \"max_features\": 2,\r\n",
    "        \"max_depth\": None,\r\n",
    "    },\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "#cl = list(range(1,5))\r\n",
    "#ca = [ f'ex{i}' for i in cl]\r\n",
    "#paramSet = { k: paramSetAll[k] for k in ca} \r\n",
    "paramSet = paramSetAll\r\n",
    "print(paramSet)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'ex1': {'criterion': 'gini', 'n_estimators': 25, 'max_samples': None, 'max_features': 'auto', 'max_depth': None}, 'ex2': {'criterion': 'gini', 'n_estimators': 100, 'max_samples': None, 'max_features': 'auto', 'max_depth': 2}, 'ex3': {'criterion': 'gini', 'n_estimators': 1000, 'max_samples': None, 'max_features': 2, 'max_depth': None}}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "for ex, paramValue in paramSet.items():\r\n",
    "    # Create object\r\n",
    "    clf = RandomForestClassifier(**paramValue)\r\n",
    "    # Training\r\n",
    "    clf.fit(X_train_std, y_train)\r\n",
    "    # Prediction\r\n",
    "    y_pred = clf.predict(X_test_std)\r\n",
    "    # Misclassification from the test samples\r\n",
    "    sumMiss = (y_test != y_pred).sum()\r\n",
    "    # Accuracy score from the test samples\r\n",
    "    accuracyScore = accuracy_score(y_test, y_pred)\r\n",
    "    print(f\"Misclassified examples: {sumMiss}\")\r\n",
    "    print(f\"Accuracy score: {accuracyScore}\")\r\n",
    "    print(\"-------------------------------------\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Misclassified examples: 1\n",
      "Accuracy score: 0.9777777777777777\n",
      "-------------------------------------\n",
      "Misclassified examples: 1\n",
      "Accuracy score: 0.9777777777777777\n",
      "-------------------------------------\n",
      "Misclassified examples: 1\n",
      "Accuracy score: 0.9777777777777777\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "be725e0de8fb3f5fda9b0118bdf797fa9814e28e467c1cce77c5b9910d8a1786"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}